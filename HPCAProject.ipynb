{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x039BrVQgHDI",
        "outputId": "5d950f96-6053-46e1-8856-c276492ad372"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5k7mvPUVjEoL",
        "outputId": "f35445b8-1f32-40e5-8eea-9ab74011b4e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset extracted successfully!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Unzip the dataset\n",
        "zip_path = \"/content/pda-159-dataset.zip\"\n",
        "extract_path = \"/content/\"\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(\"Dataset extracted successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NIQJ9-rIjT1q"
      },
      "outputs": [],
      "source": [
        "\n",
        "from Cache import Cache\n",
        "from DataLoader import DataLoaderPintos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KfpV5ooTjguj"
      },
      "outputs": [],
      "source": [
        "dataloader = DataLoaderPintos([\"pda-159-dataset/filesys/extended/dir-open.csv\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UYUK6l0Ok-Qh"
      },
      "outputs": [],
      "source": [
        "from ReflexAgent import LRUAgent, LFUAgent, MRUAgent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "cFszwtU_oQMr"
      },
      "outputs": [],
      "source": [
        "env = Cache(dataloader, 50,\n",
        "            feature_selection=('Base',),\n",
        "            reward_params=dict(name='our', alpha=0.5, psi=10, mu=1, beta=0.3),\n",
        "            allow_skip=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JC7XUI3NpAy5",
        "outputId": "d35219ad-375c-408a-ef74-a09aea667ee9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------- LRU --------------------\n",
            "Agent=LRU: Miss Rate=0.1994514106583072\n",
            "-------------------- LFU --------------------\n",
            "Agent=LFU: Miss Rate=0.1841692789968652\n",
            "-------------------- MRU --------------------\n",
            "Agent=MRU: Miss Rate=0.4647335423197492\n",
            "Best Agent: LFU with Miss Rate=0.1841692789968652\n"
          ]
        }
      ],
      "source": [
        "\n",
        "agents = {\n",
        "    'LRU': LRUAgent(env.n_actions),\n",
        "    'LFU': LFUAgent(env.n_actions),\n",
        "    'MRU': MRUAgent(env.n_actions)\n",
        "}\n",
        "\n",
        "miss_rates = {}\n",
        "\n",
        "for name, agent in agents.items():\n",
        "    print(f\"-------------------- {name} --------------------\")\n",
        "\n",
        "    # Reset environment\n",
        "    observation = env.reset()\n",
        "\n",
        "# Run simulation\n",
        "    while not env.hasDone():\n",
        "        action = agent.choose_action(observation)\n",
        "        observation_, reward = env.step(action)\n",
        "        observation = observation_\n",
        "\n",
        "    # Record miss rate\n",
        "    miss_rate = env.miss_rate()\n",
        "    miss_rates[name] = miss_rate\n",
        "\n",
        "    print(f\"Agent={name}: Miss Rate={miss_rate}\")\n",
        "\n",
        "# Compare miss rates\n",
        "best_agent = min(miss_rates, key=miss_rates.get)\n",
        "print(f\"Best Agent: {best_agent} with Miss Rate={miss_rates[best_agent]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ND1cb6ft4UoC",
        "outputId": "c1dfce06-9f07-4228-910b-86267870b65d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================== Final Evaluation ==================\n",
            "DQN Miss Rate after 10 episodes: 0.141066\n"
          ]
        }
      ],
      "source": [
        "from DQNAgent import DQNAgent\n",
        "from Cache import Cache\n",
        "from DataLoader import DataLoaderPintos\n",
        "data_loader = DataLoaderPintos(\"pda-159-dataset/filesys/extended/dir-open.csv\", boot=False)  # or your own file\n",
        "\n",
        "env = Cache(\n",
        "    requests=data_loader,\n",
        "    cache_size=100,\n",
        "    feature_selection=('Base','Age','Frequency'),\n",
        "    reward_params=dict(name='our', alpha=0.5, psi=10, mu=1, beta=0.3)\n",
        ")\n",
        "\n",
        "# Initialize DQN agent\n",
        "dqn_agent = DQNAgent(\n",
        "    n_actions=env.n_actions,\n",
        "    n_features=len(env.reset()['features']),\n",
        "    learning_rate=0.005,\n",
        "    reward_decay=0.9,\n",
        "    e_greedy_min=(0.05, 0.1),\n",
        "    e_greedy_max=(0.2, 0.3),\n",
        "    e_greedy_init=(0.1, 0.2),\n",
        "    e_greedy_increment=(0.01, 0.01),\n",
        "    e_greedy_decrement=(0.005, 0.005),\n",
        "    reward_threshold=5,\n",
        "    explore_mentor='LRU',\n",
        "    replace_target_iter=200,\n",
        "    memory_size=10000,\n",
        "    batch_size=32,\n",
        "    output_graph=False,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Train the DQN agent over multiple episodes\n",
        "episodes = 10\n",
        "for ep in range(episodes):\n",
        "    observation = env.reset()\n",
        "    while not env.hasDone():\n",
        "        action = dqn_agent.choose_action(observation)\n",
        "        observation_, reward = env.step(action)\n",
        "        dqn_agent.store_transition(observation, action, reward, observation_)\n",
        "        dqn_agent.learn()\n",
        "        observation = observation_\n",
        "\n",
        "# Final evaluation after training\n",
        "final_observation = env.reset()\n",
        "while not env.hasDone():\n",
        "    action = dqn_agent.choose_action(final_observation)\n",
        "    final_observation, _ = env.step(action)\n",
        "\n",
        "# Print final miss rate\n",
        "print(\"\\n================== Final Evaluation ==================\")\n",
        "print(f\"DQN Miss Rate after {episodes} episodes: {env.miss_rate():.6f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_TQiI70tyulx"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
